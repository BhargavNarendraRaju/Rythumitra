{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q0IHvN51ejyp",
        "outputId": "cf103b2a-280c-4264-a3e5-fb6a876323bb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting streamlit\n",
            "  Downloading streamlit-1.48.1-py3-none-any.whl.metadata (9.5 kB)\n",
            "Requirement already satisfied: altair!=5.4.0,!=5.4.1,<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<7,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (8.2.1)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.0.2)\n",
            "Requirement already satisfied: packaging<26,>=20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (25.0)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.2.2)\n",
            "Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (11.3.0)\n",
            "Requirement already satisfied: protobuf<7,>=3.20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.29.5)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (18.1.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.32.3)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (9.1.2)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (4.14.1)\n",
            "Collecting watchdog<7,>=2.1.5 (from streamlit)\n",
            "  Downloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl.metadata (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.11/dist-packages (from streamlit) (3.1.45)\n",
            "Collecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
            "  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: tornado!=6.5.0,<7,>=6.0.3 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (3.1.6)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.11/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (4.25.0)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.11/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (2.1.1)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2025.8.3)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (3.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (0.27.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n",
            "Downloading streamlit-1.48.1-py3-none-any.whl (9.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.9/9.9 MB\u001b[0m \u001b[31m99.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m132.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl (79 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.1/79.1 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: watchdog, pydeck, streamlit\n",
            "Successfully installed pydeck-0.9.1 streamlit-1.48.1 watchdog-6.0.0\n",
            "--2025-08-18 17:50:42--  https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-amd64.deb\n",
            "Resolving github.com (github.com)... 140.82.116.4\n",
            "Connecting to github.com (github.com)|140.82.116.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://github.com/cloudflare/cloudflared/releases/download/2025.8.0/cloudflared-linux-amd64.deb [following]\n",
            "--2025-08-18 17:50:42--  https://github.com/cloudflare/cloudflared/releases/download/2025.8.0/cloudflared-linux-amd64.deb\n",
            "Reusing existing connection to github.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://release-assets.githubusercontent.com/github-production-release-asset/106867604/f921b818-5fdc-49bd-a746-f2968f21afd8?sp=r&sv=2018-11-09&sr=b&spr=https&se=2025-08-18T18%3A45%3A13Z&rscd=attachment%3B+filename%3Dcloudflared-linux-amd64.deb&rsct=application%2Foctet-stream&skoid=96c2d410-5711-43a1-aedd-ab1947aa7ab0&sktid=398a6654-997b-47e9-b12b-9515b896b4de&skt=2025-08-18T17%3A44%3A29Z&ske=2025-08-18T18%3A45%3A13Z&sks=b&skv=2018-11-09&sig=EgCJ9LidtvpJCcLPt8QX%2BHUQ9wG%2FjnHMJz%2BrC2gka7g%3D&jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmVsZWFzZS1hc3NldHMuZ2l0aHVidXNlcmNvbnRlbnQuY29tIiwia2V5Ijoia2V5MSIsImV4cCI6MTc1NTUzOTc0MiwibmJmIjoxNzU1NTM5NDQyLCJwYXRoIjoicmVsZWFzZWFzc2V0cHJvZHVjdGlvbi5ibG9iLmNvcmUud2luZG93cy5uZXQifQ.eCmdCWqAwBKOrNHGT7wCUEvBxOpzM-BzYqTv9q_9278&response-content-disposition=attachment%3B%20filename%3Dcloudflared-linux-amd64.deb&response-content-type=application%2Foctet-stream [following]\n",
            "--2025-08-18 17:50:42--  https://release-assets.githubusercontent.com/github-production-release-asset/106867604/f921b818-5fdc-49bd-a746-f2968f21afd8?sp=r&sv=2018-11-09&sr=b&spr=https&se=2025-08-18T18%3A45%3A13Z&rscd=attachment%3B+filename%3Dcloudflared-linux-amd64.deb&rsct=application%2Foctet-stream&skoid=96c2d410-5711-43a1-aedd-ab1947aa7ab0&sktid=398a6654-997b-47e9-b12b-9515b896b4de&skt=2025-08-18T17%3A44%3A29Z&ske=2025-08-18T18%3A45%3A13Z&sks=b&skv=2018-11-09&sig=EgCJ9LidtvpJCcLPt8QX%2BHUQ9wG%2FjnHMJz%2BrC2gka7g%3D&jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmVsZWFzZS1hc3NldHMuZ2l0aHVidXNlcmNvbnRlbnQuY29tIiwia2V5Ijoia2V5MSIsImV4cCI6MTc1NTUzOTc0MiwibmJmIjoxNzU1NTM5NDQyLCJwYXRoIjoicmVsZWFzZWFzc2V0cHJvZHVjdGlvbi5ibG9iLmNvcmUud2luZG93cy5uZXQifQ.eCmdCWqAwBKOrNHGT7wCUEvBxOpzM-BzYqTv9q_9278&response-content-disposition=attachment%3B%20filename%3Dcloudflared-linux-amd64.deb&response-content-type=application%2Foctet-stream\n",
            "Resolving release-assets.githubusercontent.com (release-assets.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to release-assets.githubusercontent.com (release-assets.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 20175752 (19M) [application/octet-stream]\n",
            "Saving to: ‘cloudflared-linux-amd64.deb’\n",
            "\n",
            "cloudflared-linux-a 100%[===================>]  19.24M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2025-08-18 17:50:42 (177 MB/s) - ‘cloudflared-linux-amd64.deb’ saved [20175752/20175752]\n",
            "\n",
            "Selecting previously unselected package cloudflared.\n",
            "(Reading database ... 126380 files and directories currently installed.)\n",
            "Preparing to unpack cloudflared-linux-amd64.deb ...\n",
            "Unpacking cloudflared (2025.8.0) ...\n",
            "Setting up cloudflared (2025.8.0) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n"
          ]
        }
      ],
      "source": [
        "!pip install streamlit\n",
        "!wget https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-amd64.deb\n",
        "!dpkg -i cloudflared-linux-amd64.deb\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2nygXeSYzTUv",
        "outputId": "85de0e31-51d3-4847-f8fc-62b8782c2a31"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/981.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━\u001b[0m \u001b[32m921.6/981.5 kB\u001b[0m \u001b[31m27.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m152.0/152.0 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.8/73.8 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.7/88.7 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m51.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.2/75.2 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m779.6/779.6 kB\u001b[0m \u001b[31m38.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m680.8/680.8 kB\u001b[0m \u001b[31m22.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m635.4/635.4 kB\u001b[0m \u001b[31m42.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m49.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.7/44.7 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m53.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m57.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m266.2/266.2 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.0/105.0 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.1/140.1 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.0/14.0 MB\u001b[0m \u001b[31m50.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.3/85.3 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for htbuilder (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install -q streamlit langchain pydantic fastapi uvicorn geopy langdetect transformers earthengine-api pyngrok requests streamlit-js-eval streamlit-extras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "eppFgfP82Osc"
      },
      "outputs": [],
      "source": [
        "import ee\n",
        "ee.Authenticate() # Try authenticating manually\n",
        "ee.Initialize(project='ee-bhargavnarendraraju')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3vnEQDV2G0Hz",
        "outputId": "b1d0e917-e15e-477e-f988-1d5dcb08f7cb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting streamlit-lottie\n",
            "  Downloading streamlit_lottie-0.0.5-py3-none-any.whl.metadata (3.3 kB)\n",
            "Requirement already satisfied: streamlit-js-eval in /usr/local/lib/python3.11/dist-packages (0.1.7)\n",
            "Requirement already satisfied: geopy in /usr/local/lib/python3.11/dist-packages (2.4.1)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.55.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (2.32.3)\n",
            "Requirement already satisfied: streamlit>=0.63 in /usr/local/lib/python3.11/dist-packages (from streamlit-lottie) (1.48.1)\n",
            "Requirement already satisfied: geographiclib<3,>=1.52 in /usr/local/lib/python3.11/dist-packages (from geopy) (2.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.34.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.4)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.6.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.14.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Collecting nvidia-nccl-cu12==2.21.5 (from torch)\n",
            "  Downloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests) (2025.8.3)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.7)\n",
            "Requirement already satisfied: altair!=5.4.0,!=5.4.1,<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit>=0.63->streamlit-lottie) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from streamlit>=0.63->streamlit-lottie) (1.9.0)\n",
            "Requirement already satisfied: cachetools<7,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit>=0.63->streamlit-lottie) (5.5.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit>=0.63->streamlit-lottie) (8.2.1)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit>=0.63->streamlit-lottie) (2.2.2)\n",
            "Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit>=0.63->streamlit-lottie) (11.3.0)\n",
            "Requirement already satisfied: protobuf<7,>=3.20 in /usr/local/lib/python3.11/dist-packages (from streamlit>=0.63->streamlit-lottie) (5.29.5)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit>=0.63->streamlit-lottie) (18.1.0)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit>=0.63->streamlit-lottie) (9.1.2)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.11/dist-packages (from streamlit>=0.63->streamlit-lottie) (0.10.2)\n",
            "Requirement already satisfied: watchdog<7,>=2.1.5 in /usr/local/lib/python3.11/dist-packages (from streamlit>=0.63->streamlit-lottie) (6.0.0)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.11/dist-packages (from streamlit>=0.63->streamlit-lottie) (3.1.45)\n",
            "Requirement already satisfied: pydeck<1,>=0.8.0b4 in /usr/local/lib/python3.11/dist-packages (from streamlit>=0.63->streamlit-lottie) (0.9.1)\n",
            "Requirement already satisfied: tornado!=6.5.0,<7,>=6.0.3 in /usr/local/lib/python3.11/dist-packages (from streamlit>=0.63->streamlit-lottie) (6.4.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.11/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit>=0.63->streamlit-lottie) (4.25.0)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.11/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit>=0.63->streamlit-lottie) (2.1.1)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit>=0.63->streamlit-lottie) (4.0.12)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit>=0.63->streamlit-lottie) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit>=0.63->streamlit-lottie) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit>=0.63->streamlit-lottie) (2025.2)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit>=0.63->streamlit-lottie) (5.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit>=0.63->streamlit-lottie) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit>=0.63->streamlit-lottie) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit>=0.63->streamlit-lottie) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit>=0.63->streamlit-lottie) (0.27.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit>=0.63->streamlit-lottie) (1.17.0)\n",
            "Downloading streamlit_lottie-0.0.5-py3-none-any.whl (802 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m802.4/802.4 kB\u001b[0m \u001b[31m21.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m60.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m56.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m46.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl (188.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.7/188.7 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m76.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, streamlit-lottie\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-nccl-cu12\n",
            "    Found existing installation: nvidia-nccl-cu12 2.23.4\n",
            "    Uninstalling nvidia-nccl-cu12-2.23.4:\n",
            "      Successfully uninstalled nvidia-nccl-cu12-2.23.4\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nccl-cu12-2.21.5 nvidia-nvjitlink-cu12-12.4.127 streamlit-lottie-0.0.5\n"
          ]
        }
      ],
      "source": [
        "!pip install streamlit-lottie streamlit-js-eval geopy transformers torch requests"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C1e62tcA4CKl",
        "outputId": "4fd54282-a328-4cd8-da5e-f34b9f478148"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting timezonefinder\n",
            "  Downloading timezonefinder-8.0.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.2 kB)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.11/dist-packages (from timezonefinder) (2.0.2)\n",
            "Collecting h3>4 (from timezonefinder)\n",
            "  Downloading h3-4.3.1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (18 kB)\n",
            "Requirement already satisfied: cffi<2,>=1.15.1 in /usr/local/lib/python3.11/dist-packages (from timezonefinder) (1.17.1)\n",
            "Requirement already satisfied: flatbuffers>=25.2.10 in /usr/local/lib/python3.11/dist-packages (from timezonefinder) (25.2.10)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi<2,>=1.15.1->timezonefinder) (2.22)\n",
            "Downloading timezonefinder-8.0.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (28.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m28.0/28.0 MB\u001b[0m \u001b[31m72.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading h3-4.3.1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m62.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: h3, timezonefinder\n",
            "Successfully installed h3-4.3.1 timezonefinder-8.0.0\n"
          ]
        }
      ],
      "source": [
        "!pip install timezonefinder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W3GFuWBnEIIL",
        "outputId": "472730d7-5f7c-4f1d-a4b7-d97b9b9bfa63"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing capital_man.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile capital_man.py\n",
        "\n",
        "import json\n",
        "import time\n",
        "import torch\n",
        "import logging\n",
        "import requests\n",
        "from datetime import datetime\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
        "from geopy.geocoders import Nominatim\n",
        "import streamlit as st\n",
        "from streamlit_js_eval import get_geolocation\n",
        "\n",
        "# Configure logging\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# ----------------------------\n",
        "# Configuration\n",
        "# ----------------------------\n",
        "MODEL_REGISTRY = {\n",
        "    \"ASA – Policy Specialist\": {\n",
        "        \"id\": \"KissanAI/ThinkingDhenu1-CRSA-India-preview\",\n",
        "        \"role\": \"specialist-policy\",\n",
        "        \"color\": \"#27AE60\",\n",
        "        \"requires_trust\": True,\n",
        "        \"format\": \"mistral\"\n",
        "    },\n",
        "    \"ASB – Agronomy Specialist\": {\n",
        "        \"id\": \"KissanAI/Dhenu2-In-Llama3.2-3B-Instruct\",\n",
        "        \"role\": \"specialist-agronomy\",\n",
        "        \"color\": \"#E67E22\",\n",
        "        \"requires_trust\": True,\n",
        "        \"format\": \"llama3\"\n",
        "    },\n",
        "    \"ASC – Fact Checker\": {\n",
        "        \"id\": \"bharatgenai/AgriParam\",\n",
        "        \"role\": \"specialist-crosscheck\",\n",
        "        \"color\": \"#C0392B\",\n",
        "        \"requires_trust\": True,\n",
        "        \"format\": \"mistral\"\n",
        "    }\n",
        "}\n",
        "\n",
        "ROUTER_OPTIONS = [\"Auto (Router decides)\"] + list(MODEL_REGISTRY.keys())\n",
        "WEATHER_API_KEY = \"b10a43e49ad59f27140d077c8f1a6bfd\"  # Replace with your actual API key\n",
        "\n",
        "# ----------------------------\n",
        "# Language detection\n",
        "# ----------------------------\n",
        "def detect_lang_from_text(text: str) -> str:\n",
        "    \"\"\"Detect language from text with Telugu priority\"\"\"\n",
        "    t = (text or \"\").lower()\n",
        "    if \"telugu\" in t or \"తెలుగు\" in t or any(char in t for char in [\"ఆ\", \"ఇ\", \"ఈ\", \"ఉ\", \"ఊ\"]):\n",
        "        return \"Telugu\"\n",
        "    return \"English\"\n",
        "\n",
        "# ----------------------------\n",
        "# Geocoding Helper\n",
        "# ----------------------------\n",
        "@st.cache_resource(show_spinner=False, max_entries=10)\n",
        "def reverse_geocode(lat: float, lon: float) -> tuple:\n",
        "    try:\n",
        "        geolocator = Nominatim(user_agent=\"agrobot_geolocator\")\n",
        "        location = geolocator.reverse((lat, lon), language=\"en\", exactly_one=True)\n",
        "        if location and location.raw and \"address\" in location.raw:\n",
        "            addr = location.raw[\"address\"]\n",
        "            return (\n",
        "                addr.get(\"state\", \"\"),\n",
        "                addr.get(\"county\", addr.get(\"state_district\", \"\")),\n",
        "                addr.get(\"village\", addr.get(\"town\", addr.get(\"city\", \"\"))))\n",
        "        return (\"\", \"\", \"\")\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Geocoding error: {e}\")\n",
        "        return (\"\", \"\", \"\")\n",
        "\n",
        "# ----------------------------\n",
        "# Weather Data\n",
        "# ----------------------------\n",
        "def get_current_weather(lat: float, lon: float) -> dict:\n",
        "    \"\"\"Get current weather data from OpenWeatherMap\"\"\"\n",
        "    try:\n",
        "        url = f\"https://api.openweathermap.org/data/2.5/weather?lat={lat}&lon={lon}&appid={WEATHER_API_KEY}&units=metric\"\n",
        "        response = requests.get(url, timeout=10)\n",
        "        if response.status_code == 200:\n",
        "            data = response.json()\n",
        "            return {\n",
        "                \"temp\": data[\"main\"][\"temp\"],\n",
        "                \"feels_like\": data[\"main\"][\"feels_like\"],\n",
        "                \"humidity\": data[\"main\"][\"humidity\"],\n",
        "                \"conditions\": data[\"weather\"][0][\"description\"],\n",
        "                \"wind_speed\": data[\"wind\"][\"speed\"],\n",
        "                \"icon\": data[\"weather\"][0][\"icon\"]\n",
        "            }\n",
        "        return {}\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Weather API error: {e}\")\n",
        "        return {}\n",
        "\n",
        "def get_weather_icon(icon_code: str) -> str:\n",
        "    \"\"\"Get weather icon from code\"\"\"\n",
        "    icon_map = {\n",
        "        \"01d\": \"☀️\", \"01n\": \"🌙\", \"02d\": \"⛅\", \"02n\": \"⛅\",\n",
        "        \"03d\": \"☁️\", \"03n\": \"☁️\", \"04d\": \"☁️\", \"04n\": \"☁️\",\n",
        "        \"09d\": \"🌧️\", \"09n\": \"🌧️\", \"10d\": \"🌦️\", \"10n\": \"🌦️\",\n",
        "        \"11d\": \"⛈️\", \"11n\": \"⛈️\", \"13d\": \"❄️\", \"13n\": \"❄️\",\n",
        "        \"50d\": \"🌫️\", \"50n\": \"🌫️\"\n",
        "    }\n",
        "    return icon_map.get(icon_code, \"🌡️\")\n",
        "\n",
        "# ----------------------------\n",
        "# Model Loading and Inference\n",
        "# ----------------------------\n",
        "@st.cache_resource(show_spinner=False)\n",
        "def load_model(model_id: str, requires_trust: bool):\n",
        "    \"\"\"Load model efficiently with quantization\"\"\"\n",
        "    try:\n",
        "        logger.info(f\"Loading model: {model_id}\")\n",
        "\n",
        "        # Load tokenizer\n",
        "        tokenizer = AutoTokenizer.from_pretrained(model_id, trust_remote_code=requires_trust)\n",
        "\n",
        "        # Load model with 4-bit quantization\n",
        "        model = AutoModelForCausalLM.from_pretrained(\n",
        "            model_id,\n",
        "            torch_dtype=torch.float16,\n",
        "            device_map=\"auto\",\n",
        "            load_in_4bit=True,\n",
        "            trust_remote_code=requires_trust\n",
        "        )\n",
        "\n",
        "        logger.info(f\"Successfully loaded model: {model_id}\")\n",
        "        return tokenizer, model\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Model loading error for {model_id}: {e}\")\n",
        "        # Fallback without quantization\n",
        "        try:\n",
        "            model = AutoModelForCausalLM.from_pretrained(\n",
        "                model_id,\n",
        "                torch_dtype=torch.float16,\n",
        "                device_map=\"auto\",\n",
        "                trust_remote_code=requires_trust\n",
        "            )\n",
        "            return tokenizer, model\n",
        "        except Exception as e2:\n",
        "            logger.error(f\"Fallback loading failed: {e2}\")\n",
        "            return None, None\n",
        "\n",
        "def generate_text(tokenizer, model, prompt: str, max_new_tokens: int = 256, temperature: float = 0.7) -> str:\n",
        "    \"\"\"Generate text using the model (optimized)\"\"\"\n",
        "    try:\n",
        "        # Tokenize\n",
        "        inputs = tokenizer(\n",
        "            prompt,\n",
        "            return_tensors=\"pt\",\n",
        "            truncation=True,\n",
        "            max_length=512,\n",
        "            padding=True\n",
        "        ).to(model.device)\n",
        "\n",
        "        # Generate response\n",
        "        outputs = model.generate(\n",
        "            **inputs,\n",
        "            max_new_tokens=max_new_tokens,\n",
        "            do_sample=True,\n",
        "            temperature=temperature,\n",
        "            top_p=0.9,\n",
        "            pad_token_id=tokenizer.eos_token_id\n",
        "        )\n",
        "\n",
        "        # Decode only the new tokens (after input length)\n",
        "        input_length = inputs.input_ids.shape[1]\n",
        "        response = tokenizer.decode(\n",
        "            outputs[0][input_length:],\n",
        "            skip_special_tokens=True\n",
        "        )\n",
        "\n",
        "        # Clean up common artifacts\n",
        "        stop_phrases = [\"<|end|>\", \"<|eot_id|>\", \"###\", \"Human:\", \"Assistant:\", \"\\nUser:\", \"\\nSystem:\"]\n",
        "        for phrase in stop_phrases:\n",
        "            response = response.replace(phrase, \"\").strip()\n",
        "\n",
        "        return response\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Generation error: {e}\")\n",
        "        return f\"Generation error: {str(e)}\"\n",
        "\n",
        "def format_prompt(model_format: str, system_prompt: str, user_query: str, weather_info: dict) -> str:\n",
        "    \"\"\"Format prompt according to model requirements with weather context\"\"\"\n",
        "    weather_context = \"\"\n",
        "    if weather_info:\n",
        "        temp = weather_info.get(\"temp\", \"N/A\")\n",
        "        conditions = weather_info.get(\"conditions\", \"N/A\")\n",
        "        humidity = weather_info.get(\"humidity\", \"N/A\")\n",
        "        wind = weather_info.get(\"wind_speed\", \"N/A\")\n",
        "        weather_context = f\"\\nCurrent Weather: {conditions}, Temp: {temp}°C, Humidity: {humidity}%, Wind: {wind} km/h\"\n",
        "\n",
        "    full_system_prompt = system_prompt + weather_context\n",
        "\n",
        "    if model_format == \"llama3\":\n",
        "        return f\"\"\"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
        "        {full_system_prompt}\n",
        "        <|eot_id|><|start_header_id|>user<|end_header_id|>\n",
        "        {user_query}\n",
        "        <|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
        "        \"\"\"\n",
        "    elif model_format == \"mistral\":\n",
        "        return f\"<s>[INST] {full_system_prompt}\\n\\n{user_query} [/INST]\"\n",
        "    else:\n",
        "        return f\"System: {full_system_prompt}\\n\\nUser: {user_query}\\n\\nAssistant:\"\n",
        "\n",
        "def call_model_chat(model_info: dict, system_prompt: str, user_query: str, weather_info: dict, max_new_tokens: int = 256, temperature: float = 0.7) -> str:\n",
        "    \"\"\"Call actual LLM for response generation\"\"\"\n",
        "    tokenizer, model = load_model(model_info[\"id\"], model_info[\"requires_trust\"])\n",
        "    if tokenizer is None or model is None:\n",
        "        return \"Model loading failed\"\n",
        "\n",
        "    # Format prompt according to model requirements\n",
        "    prompt = format_prompt(model_info[\"format\"], system_prompt, user_query, weather_info)\n",
        "\n",
        "    return generate_text(tokenizer, model, prompt, max_new_tokens, temperature)\n",
        "\n",
        "# ----------------------------\n",
        "# Simplified Routing\n",
        "# ----------------------------\n",
        "def enhanced_router(query: str) -> str:\n",
        "    \"\"\"Optimized routing with keyword matching\"\"\"\n",
        "    q = (query or \"\").lower()\n",
        "\n",
        "    # Policy/subsidy related queries\n",
        "    policy_keywords = [\"policy\", \"subsidy\", \"pm-kisan\", \"scheme\", \"mandi\",\n",
        "                      \"insurance\", \"price\", \"loan\", \"government\", \"yojana\", \"benefit\"]\n",
        "    if any(k in q for k in policy_keywords):\n",
        "        return \"ASA – Policy Specialist\"\n",
        "\n",
        "    # Verification/fact-checking\n",
        "    verification_keywords = [\"verify\", \"cross-check\", \"double check\", \"correct\",\n",
        "                            \"fact check\", \"source\", \"accurate\", \"truth\", \"confirm\"]\n",
        "    if any(k in q for k in verification_keywords):\n",
        "        return \"ASC – Fact Checker\"\n",
        "\n",
        "    # Default to agronomy specialist\n",
        "    return \"ASB – Agronomy Specialist\"\n",
        "\n",
        "def route_query(query: str, router_pref: str) -> str:\n",
        "    if router_pref != \"Auto (Router decides)\":\n",
        "        return router_pref\n",
        "    return enhanced_router(query)\n",
        "\n",
        "# ----------------------------\n",
        "# Specialist Functions\n",
        "# ----------------------------\n",
        "def specialist_answer(route_code: str, query: str, state: str, district: str, language: str, weather_info: dict, max_new: int, temperature: float) -> str:\n",
        "    model_info = MODEL_REGISTRY[route_code]\n",
        "\n",
        "    # Determine final language\n",
        "    final_lang = detect_lang_from_text(query) if language == \"Auto\" else language\n",
        "\n",
        "    # System prompt based on role and language\n",
        "    if final_lang == \"Telugu\":\n",
        "        sys_prompt = (\n",
        "            f\"మీరు భారతీయ రైతులకు నిపుణ వ్యవసాయ సలహాదారు.  \\n\"\n",
        "            f\"వినియోగదారు {district}, {state} వద్ద ఉన్నారు. \\n\"\n",
        "            \"పూర్తి వాక్యాలలో స్పష్టమైన, ఆచరణాత్మక సలహా ఇవ్వండి.\"\n",
        "        )\n",
        "    else:\n",
        "        sys_prompt = (\n",
        "            f\"You are an expert agriculture advisor for Indian farmers. \\n\"\n",
        "            f\"The user is located in {district}, {state}.\\n\"\n",
        "            \"Give clear, practical advice in complete sentences.\"\n",
        "        )\n",
        "\n",
        "    return call_model_chat(model_info, sys_prompt, query, weather_info, max_new_tokens=max_new, temperature=temperature)\n",
        "\n",
        "def critic_refine(original_answer: str, query: str, language: str, weather_info: dict, max_new: int, temperature: float) -> str:\n",
        "    model_info = MODEL_REGISTRY[\"ASC – Fact Checker\"]\n",
        "\n",
        "    # Determine final language\n",
        "    final_lang = detect_lang_from_text(query) if language == \"Auto\" else language\n",
        "\n",
        "    # System prompt for critic\n",
        "    if final_lang == \"Telugu\":\n",
        "        sys_prompt = (\n",
        "            \"మీరు వ్యవసాయ సత్యాసత్యత తనిఖీదారు. ఇచ్చిన సమాధానాన్ని వాస్తవికత, సురక్షితత్వం మరియు \"\n",
        "            \"భారత సందర్భానికి అనుగుణంగా ధృవీకరించండి. \"\n",
        "            \"సరిదిద్దడం అవసరమైతే, సరిదిద్దబడిన సమాధానం ఇవ్వండి.\"\n",
        "        )\n",
        "        user_prompt = f\"అసలు సమాధానం: {original_answer}\\n\\nప్రశ్న: {query}\"\n",
        "    else:\n",
        "        sys_prompt = (\n",
        "            \"You are an agriculture fact-checker. Verify the answer for factuality, safety, and \"\n",
        "            \"Indian context. If corrections are needed, provide a corrected answer.\"\n",
        "        )\n",
        "        user_prompt = f\"Original Answer: {original_answer}\\n\\nQuestion: {query}\"\n",
        "\n",
        "    return call_model_chat(model_info, sys_prompt, user_prompt, weather_info, max_new_tokens=max_new, temperature=temperature)\n",
        "\n",
        "# ----------------------------\n",
        "# Streamlit UI\n",
        "# ----------------------------\n",
        "st.set_page_config(\n",
        "    page_title=\"Rythumitra – AI Farming Assistant\",\n",
        "    page_icon=\"🌾\",\n",
        "    layout=\"wide\",\n",
        "    initial_sidebar_state=\"expanded\"\n",
        ")\n",
        "\n",
        "# Agriculture-themed color scheme\n",
        "AGRICULTURE_THEME = {\n",
        "    \"primary\": \"#2e7d32\",        # Dark green\n",
        "    \"secondary\": \"#4caf50\",      # Medium green\n",
        "    \"accent\": \"#8bc34a\",         # Light green\n",
        "    \"background\": \"#e8f5e9\",     # Very light green\n",
        "    \"text_dark\": \"#1b5e20\",      # Dark green text\n",
        "    \"text_black\": \"#212121\",     # Black text\n",
        "    \"card_bg\": \"#ffffff\",        # White cards\n",
        "    \"border\": \"#c8e6c9\",         # Light green border\n",
        "    \"highlight\": \"#FFD54F\",      # Highlight color\n",
        "    \"sidebar_bg\": \"#1b5e20\",     # Dark green sidebar\n",
        "    \"sidebar_text\": \"#ffffff\",   # White sidebar text\n",
        "    \"weather_bg\": \"#dcedc8\"      # Weather card background\n",
        "}\n",
        "\n",
        "# Apply theme\n",
        "st.markdown(f\"\"\"\n",
        "    <style>\n",
        "    .stApp {{\n",
        "        background-color: {AGRICULTURE_THEME['background']};\n",
        "    }}\n",
        "    h1, h2, h3, h4, h5, h6 {{\n",
        "        color: {AGRICULTURE_THEME['primary']} !important;\n",
        "    }}\n",
        "    .stButton>button {{\n",
        "        background: linear-gradient(to right, {AGRICULTURE_THEME['primary']}, {AGRICULTURE_THEME['secondary']}) !important;\n",
        "        color: white !important;\n",
        "    }}\n",
        "    [data-testid=\"stSidebar\"] {{\n",
        "        background-color: {AGRICULTURE_THEME['sidebar_bg']} !important;\n",
        "    }}\n",
        "    .terminal-output {{\n",
        "        color:black;\n",
        "        background: rgba(255, 255, 255, 0.95);\n",
        "        border-left: 5px solid {AGRICULTURE_THEME['primary']};\n",
        "        padding: 15px;\n",
        "        border-radius: 0 10px 10px 0;\n",
        "    }}\n",
        "    .weather-card {{\n",
        "        background: {AGRICULTURE_THEME['weather_bg']};\n",
        "        border-radius: 12px;\n",
        "        padding: 15px;\n",
        "        margin: 15px 0;\n",
        "        box-shadow: 0 4px 6px rgba(0,0,0,0.1);\n",
        "    }}\n",
        "    .location-card {{\n",
        "        background: linear-gradient(135deg, #e8f5e9, #dcedc8);\n",
        "        padding: 15px;\n",
        "        border-radius: 12px;\n",
        "        margin-bottom: 25px;\n",
        "    }}\n",
        "    .metric-value {{\n",
        "        font-size: 1.2em;\n",
        "        font-weight: bold;\n",
        "        color: {AGRICULTURE_THEME['primary']};\n",
        "    }}\n",
        "    .metric-label {{\n",
        "        font-size: 0.9em;\n",
        "        color: {AGRICULTURE_THEME['text_dark']};\n",
        "    }}\n",
        "    </style>\n",
        "\"\"\", unsafe_allow_html=True)\n",
        "\n",
        "# Initialize session state\n",
        "if \"user_lat\" not in st.session_state:\n",
        "    st.session_state.user_lat = 17.7271  # Default: Visakhapatnam\n",
        "    st.session_state.user_lon = 83.3013\n",
        "if \"selected_route\" not in st.session_state:\n",
        "    st.session_state.selected_route = \"Auto (Router decides)\"\n",
        "if \"enable_critic\" not in st.session_state:\n",
        "    st.session_state.enable_critic = True\n",
        "if \"response_lang\" not in st.session_state:\n",
        "    st.session_state.response_lang = \"Auto\"\n",
        "if \"max_new\" not in st.session_state:\n",
        "    st.session_state.max_new = 256\n",
        "if \"temperature\" not in st.session_state:\n",
        "    st.session_state.temperature = 0.7\n",
        "if \"weather_data\" not in st.session_state:\n",
        "    st.session_state.weather_data = {}\n",
        "if \"use_browser_location\" not in st.session_state:\n",
        "    st.session_state.use_browser_location = False\n",
        "\n",
        "# Get location info\n",
        "state, district, village = reverse_geocode(st.session_state.user_lat, st.session_state.user_lon)\n",
        "location_str = f\"{village}, {district}, {state}\" if village or district or state else \"your location\"\n",
        "\n",
        "# Get weather data\n",
        "if WEATHER_API_KEY:\n",
        "    st.session_state.weather_data = get_current_weather(st.session_state.user_lat, st.session_state.user_lon)\n",
        "\n",
        "# Main UI\n",
        "st.title(\"🌾 Rythumitra — AI Farming Assistant\")\n",
        "st.markdown(f\"\"\"\n",
        "    <div class=\"location-card\">\n",
        "        <p style=\"font-size: 18px; margin: 0; color: #1b5e20; font-weight: 500;\">\n",
        "            తెలుగు & English AI Farming Assistant | Location: {location_str}\n",
        "        </p>\n",
        "    </div>\n",
        "\"\"\", unsafe_allow_html=True)\n",
        "\n",
        "# Weather display\n",
        "if st.session_state.weather_data:\n",
        "    weather = st.session_state.weather_data\n",
        "    icon = get_weather_icon(weather.get(\"icon\", \"\"))\n",
        "    st.markdown(f\"\"\"\n",
        "        <div class=\"weather-card\">\n",
        "            <div style=\"display: flex; justify-content: space-between; align-items: center;\">\n",
        "                <div>\n",
        "                    <h3 style=\"margin: 0; color: {AGRICULTURE_THEME['primary']};\">Current Weather</h3>\n",
        "                    <div style=\"font-size: 1.5em; margin: 5px 0;\">{icon} {weather.get('conditions', 'N/A').title()}</div>\n",
        "                </div>\n",
        "                <div style=\"font-size: 2.5em; font-weight: bold;\">{weather.get('temp', 'N/A')}°C</div>\n",
        "                <div>\n",
        "                    <div class=\"metric-label\">Feels Like</div>\n",
        "                    <div class=\"metric-value\">{weather.get('feels_like', 'N/A')}°C</div>\n",
        "                </div>\n",
        "                <div>\n",
        "                    <div class=\"metric-label\">Humidity</div>\n",
        "                    <div class=\"metric-value\">{weather.get('humidity', 'N/A')}%</div>\n",
        "                </div>\n",
        "                <div>\n",
        "                    <div class=\"metric-label\">Wind Speed</div>\n",
        "                    <div class=\"metric-value\">{weather.get('wind_speed', 'N/A')} km/h</div>\n",
        "                </div>\n",
        "            </div>\n",
        "        </div>\n",
        "    \"\"\", unsafe_allow_html=True)\n",
        "\n",
        "# Sidebar with organized sections\n",
        "with st.sidebar:\n",
        "    st.sidebar.title(\"⚙️ Control Panel\")\n",
        "\n",
        "    # Model Selection Section\n",
        "    st.sidebar.header(\"🧠 Model Selection\")\n",
        "    st.session_state.selected_route = st.sidebar.selectbox(\n",
        "        \"Routing Method:\",\n",
        "        options=ROUTER_OPTIONS,\n",
        "        index=ROUTER_OPTIONS.index(st.session_state.selected_route),\n",
        "        help=\"Auto routing selects the best model, or choose a specific model\"\n",
        "    )\n",
        "\n",
        "    # Show model info\n",
        "    if st.session_state.selected_route != \"Auto (Router decides)\":\n",
        "        model_info = MODEL_REGISTRY[st.session_state.selected_route]\n",
        "        st.sidebar.markdown(f\"\"\"\n",
        "            <div style=\"background: {AGRICULTURE_THEME['card_bg']};\n",
        "                        border-radius: 10px; padding: 10px; margin: 10px 0;\n",
        "                        border-left: 4px solid {model_info['color']};\">\n",
        "                <div style=\"color: {model_info['color']}; font-weight: bold;\">\n",
        "                    {st.session_state.selected_route}\n",
        "                </div>\n",
        "                <div><strong>Role:</strong> {model_info[\"role\"].replace('specialist-', '').title()}</div>\n",
        "            </div>\n",
        "        \"\"\", unsafe_allow_html=True)\n",
        "\n",
        "    # Language Settings Section\n",
        "    st.sidebar.header(\"🌐 Language Settings\")\n",
        "    st.session_state.response_lang = st.sidebar.selectbox(\n",
        "        \"Response Language:\",\n",
        "        options=[\"Auto\", \"English\", \"Telugu\"],\n",
        "        index=[\"Auto\", \"English\", \"Telugu\"].index(st.session_state.response_lang),\n",
        "        help=\"Choose response language (Auto detects from question)\"\n",
        "    )\n",
        "\n",
        "    # Processing Options Section\n",
        "    st.sidebar.header(\"⚙️ Processing Options\")\n",
        "    st.session_state.enable_critic = st.sidebar.toggle(\n",
        "        \"Enable Fact Checker\",\n",
        "        value=st.session_state.enable_critic,\n",
        "        help=\"Verify response accuracy with fact checker\"\n",
        "    )\n",
        "\n",
        "    st.session_state.max_new = st.sidebar.slider(\n",
        "        \"Response Length\",\n",
        "        128, 512, st.session_state.max_new, step=32,\n",
        "        help=\"Number of tokens in the response\"\n",
        "    )\n",
        "\n",
        "    st.session_state.temperature = st.sidebar.slider(\n",
        "        \"Temperature\",\n",
        "        0.1, 1.0, st.session_state.temperature, step=0.1,\n",
        "        help=\"Controls randomness (lower = more deterministic)\"\n",
        "    )\n",
        "\n",
        "    # Location Section\n",
        "    st.sidebar.header(\"📍 Location Setup\")\n",
        "\n",
        "    # Browser location button\n",
        "    if st.sidebar.button(\"📍 Use My Current Location\", use_container_width=True):\n",
        "        loc = get_geolocation()\n",
        "        if loc and \"coords\" in loc:\n",
        "            st.session_state.user_lat = loc[\"coords\"][\"latitude\"]\n",
        "            st.session_state.user_lon = loc[\"coords\"][\"longitude\"]\n",
        "            st.session_state.use_browser_location = True\n",
        "            st.rerun()\n",
        "\n",
        "    col1, col2 = st.sidebar.columns(2)\n",
        "    with col1:\n",
        "        st.session_state.user_lat = st.number_input(\n",
        "            \"Latitude\",\n",
        "            value=st.session_state.user_lat,\n",
        "            format=\"%.6f\",\n",
        "            key=\"lat_input\"\n",
        "        )\n",
        "    with col2:\n",
        "        st.session_state.user_lon = st.number_input(\n",
        "            \"Longitude\",\n",
        "            value=st.session_state.user_lon,\n",
        "            format=\"%.6f\",\n",
        "            key=\"lon_input\"\n",
        "        )\n",
        "\n",
        "    # Weather refresh button\n",
        "    if WEATHER_API_KEY and st.sidebar.button(\"🔄 Refresh Weather Data\", use_container_width=True):\n",
        "        st.session_state.weather_data = get_current_weather(st.session_state.user_lat, st.session_state.user_lon)\n",
        "        st.rerun()\n",
        "\n",
        "# Main content area\n",
        "st.subheader(\"💬 Ask Your Agriculture Question\")\n",
        "user_query = st.text_area(\n",
        "    \"Enter your question in English or తెలుగు\",\n",
        "    placeholder=\"e.g., When should I irrigate my paddy crop? / వరి పంటకు నేను ఎప్పుడు నీటి పారుదల చేయాలి?\",\n",
        "    height=120,\n",
        "    key=\"user_query\",\n",
        "    label_visibility=\"collapsed\"\n",
        ")\n",
        "\n",
        "\n",
        "# Submit button\n",
        "if st.button(\"🚀 Get AI-Powered Answer\", type=\"primary\", use_container_width=True):\n",
        "    if not user_query.strip():\n",
        "        st.warning(\"Please enter a question\")\n",
        "    else:\n",
        "        # Get location info\n",
        "        state, district, village = reverse_geocode(st.session_state.user_lat, st.session_state.user_lon)\n",
        "\n",
        "        # Initialize progress\n",
        "        progress_bar = st.progress(0)\n",
        "        status_text = st.empty()\n",
        "\n",
        "        # Step 1: Routing\n",
        "        status_text.text(\"Routing to specialist...\")\n",
        "        progress_bar.progress(30)\n",
        "        route_code = route_query(user_query, st.session_state.selected_route)\n",
        "        model_info = MODEL_REGISTRY[route_code]\n",
        "        model_color = model_info[\"color\"]\n",
        "\n",
        "        # Display routing info\n",
        "        st.markdown(f\"\"\"\n",
        "            <div style=\"text-align: center; padding: 15px; border-radius: 12px;\n",
        "                        background: {AGRICULTURE_THEME['card_bg']};\n",
        "                        margin-bottom: 20px;\">\n",
        "                <div style=\"font-weight: bold; color: {model_color}; font-size: 1.1em; margin-bottom: 10px;\">\n",
        "                    {route_code}\n",
        "                </div>\n",
        "                <div style=\"color: {AGRICULTURE_THEME['text_black']};\">\n",
        "                    <strong>Response Language:</strong> {st.session_state.response_lang}\n",
        "                </div>\n",
        "            </div>\n",
        "        \"\"\", unsafe_allow_html=True)\n",
        "\n",
        "        # Step 2: Specialist processing\n",
        "        status_text.text(\"Generating answer...\")\n",
        "        progress_bar.progress(60)\n",
        "        answer = specialist_answer(\n",
        "            route_code,\n",
        "            user_query,\n",
        "            state,\n",
        "            district,\n",
        "            st.session_state.response_lang,\n",
        "            st.session_state.weather_data,\n",
        "            st.session_state.max_new,\n",
        "            st.session_state.temperature\n",
        "        )\n",
        "\n",
        "        # Step 3: Critic processing\n",
        "        if st.session_state.enable_critic:\n",
        "            status_text.text(\"Verifying with fact checker...\")\n",
        "            progress_bar.progress(80)\n",
        "            answer = critic_refine(\n",
        "                answer,\n",
        "                user_query,\n",
        "                st.session_state.response_lang,\n",
        "                st.session_state.weather_data,\n",
        "                min(256, st.session_state.max_new),\n",
        "                st.session_state.temperature\n",
        "            )\n",
        "\n",
        "        progress_bar.progress(100)\n",
        "        status_text.empty()\n",
        "\n",
        "        # Display result\n",
        "        st.markdown(\"---\")\n",
        "        st.subheader(\"🌱 AI Recommendation\" if st.session_state.response_lang != \"Telugu\" else \"🌱 AI సిఫార్సు\")\n",
        "        st.markdown(f'<div class=\"terminal-output\">{answer}</div>', unsafe_allow_html=True)\n",
        "\n",
        "# Footer\n",
        "st.markdown(\"---\")\n",
        "st.markdown(f\"\"\"\n",
        "    <div style=\"text-align: center; color: {AGRICULTURE_THEME['text_dark']}; font-size: 0.9em; padding: 20px;\">\n",
        "        <div style=\"display: flex; justify-content: center; gap: 20px; margin-bottom: 10px; margin-top: 20px;\">\n",
        "            <span style=\"display: flex; align-items: center;\">🌐 తెలుగు & English Support</span>\n",
        "            <span style=\"display: flex; align-items: center;\">🌦️ Live Weather Integration</span>\n",
        "            <span style=\"display: flex; align-items: center;\">📍 Location-aware Advice</span>\n",
        "            <span style=\"display: flex; align-items: center;\">⚡ Optimized Performance</span>\n",
        "        </div>\n",
        "        <div>Rythumitra AI Assistant v8.0 • Powered by KissanAI</div>\n",
        "    </div>\n",
        "\"\"\", unsafe_allow_html=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "skVtQJO2MEsr",
        "outputId": "115414a8-bd8b-43be-f8dd-ea93357bf2b3"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[90m2025-08-18T17:58:08Z\u001b[0m \u001b[32mINF\u001b[0m Thank you for trying Cloudflare Tunnel. Doing so, without a Cloudflare account, is a quick way to experiment and try it out. However, be aware that these account-less Tunnels have no uptime guarantee, are subject to the Cloudflare Online Services Terms of Use (https://www.cloudflare.com/website-terms/), and Cloudflare reserves the right to investigate your use of Tunnels for violations of such terms. If you intend to use Tunnels in production you should use a pre-created named tunnel by following: https://developers.cloudflare.com/cloudflare-one/connections/connect-apps\n",
            "\u001b[90m2025-08-18T17:58:08Z\u001b[0m \u001b[32mINF\u001b[0m Requesting new quick Tunnel on trycloudflare.com...\n",
            "\u001b[90m2025-08-18T17:58:13Z\u001b[0m \u001b[32mINF\u001b[0m +--------------------------------------------------------------------------------------------+\n",
            "\u001b[90m2025-08-18T17:58:13Z\u001b[0m \u001b[32mINF\u001b[0m |  Your quick Tunnel has been created! Visit it at (it may take some time to be reachable):  |\n",
            "\u001b[90m2025-08-18T17:58:13Z\u001b[0m \u001b[32mINF\u001b[0m |  https://widespread-distributors-compression-donor.trycloudflare.com                       |\n",
            "\u001b[90m2025-08-18T17:58:13Z\u001b[0m \u001b[32mINF\u001b[0m +--------------------------------------------------------------------------------------------+\n",
            "\u001b[90m2025-08-18T17:58:13Z\u001b[0m \u001b[32mINF\u001b[0m Cannot determine default configuration path. No file [config.yml config.yaml] in [~/.cloudflared ~/.cloudflare-warp ~/cloudflare-warp /etc/cloudflared /usr/local/etc/cloudflared]\n",
            "\u001b[90m2025-08-18T17:58:13Z\u001b[0m \u001b[32mINF\u001b[0m Version 2025.8.0 (Checksum c7d3a69da0f7b9b1bc1ddcb0597d3552bcd7c15f8bbaba463dc489b94b7544ee)\n",
            "\u001b[90m2025-08-18T17:58:13Z\u001b[0m \u001b[32mINF\u001b[0m GOOS: linux, GOVersion: go1.24.4, GoArch: amd64\n",
            "\u001b[90m2025-08-18T17:58:13Z\u001b[0m \u001b[32mINF\u001b[0m Settings: map[ha-connections:1 no-autoupdate:true protocol:quic url:http://localhost:8501]\n",
            "\u001b[90m2025-08-18T17:58:13Z\u001b[0m \u001b[32mINF\u001b[0m cloudflared will not automatically update if installed by a package manager.\n",
            "\u001b[90m2025-08-18T17:58:13Z\u001b[0m \u001b[32mINF\u001b[0m Generated Connector ID: 910516dd-0cf7-4483-82b6-a59c2a172c71\n",
            "\u001b[90m2025-08-18T17:58:13Z\u001b[0m \u001b[32mINF\u001b[0m Initial protocol quic\n",
            "\u001b[90m2025-08-18T17:58:13Z\u001b[0m \u001b[32mINF\u001b[0m ICMP proxy will use 172.28.0.12 as source for IPv4\n",
            "\u001b[90m2025-08-18T17:58:13Z\u001b[0m \u001b[32mINF\u001b[0m ICMP proxy will use :: as source for IPv6\n",
            "\u001b[90m2025-08-18T17:58:13Z\u001b[0m \u001b[1m\u001b[31mERR\u001b[0m\u001b[0m Cannot determine default origin certificate path. No file cert.pem in [~/.cloudflared ~/.cloudflare-warp ~/cloudflare-warp /etc/cloudflared /usr/local/etc/cloudflared]. You need to specify the origin certificate path by specifying the origincert option in the configuration file, or set TUNNEL_ORIGIN_CERT environment variable \u001b[36moriginCertPath=\u001b[0m\n",
            "\u001b[90m2025-08-18T17:58:13Z\u001b[0m \u001b[32mINF\u001b[0m ICMP proxy will use 172.28.0.12 as source for IPv4\n",
            "\u001b[90m2025-08-18T17:58:13Z\u001b[0m \u001b[32mINF\u001b[0m ICMP proxy will use :: as source for IPv6\n",
            "\u001b[90m2025-08-18T17:58:13Z\u001b[0m \u001b[32mINF\u001b[0m Starting metrics server on 127.0.0.1:20241/metrics\n",
            "\u001b[90m2025-08-18T17:58:13Z\u001b[0m \u001b[32mINF\u001b[0m Tunnel connection curve preferences: [X25519MLKEM768 CurveP256] \u001b[36mconnIndex=\u001b[0m0 \u001b[36mevent=\u001b[0m0 \u001b[36mip=\u001b[0m198.41.200.13\n",
            "2025/08/18 17:58:13 failed to sufficiently increase receive buffer size (was: 208 kiB, wanted: 7168 kiB, got: 416 kiB). See https://github.com/quic-go/quic-go/wiki/UDP-Buffer-Sizes for details.\n",
            "\u001b[90m2025-08-18T17:58:13Z\u001b[0m \u001b[32mINF\u001b[0m Registered tunnel connection \u001b[36mconnIndex=\u001b[0m0 \u001b[36mconnection=\u001b[0mfa329768-9899-4a18-b886-18cd4bf94999 \u001b[36mevent=\u001b[0m0 \u001b[36mip=\u001b[0m198.41.200.13 \u001b[36mlocation=\u001b[0msea06 \u001b[36mprotocol=\u001b[0mquic\n"
          ]
        }
      ],
      "source": [
        "# Run your app (adjust filename)\n",
        "!streamlit run capital_man.py --server.port 8501 &>/content/logs.txt &\n",
        "\n",
        "# Expose via Cloudflare Tunnel\n",
        "!cloudflared tunnel --url http://localhost:8501 --no-autoupdate\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}